{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Environment Setup and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00374/energydata_complete.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data = data.drop(columns=['date'])  # Remove the date column\n",
    "\n",
    "# Select a subset of features for simplicity\n",
    "features = ['T1', 'RH_1', 'T2', 'RH_2', 'T3', 'RH_3', 'Appliances']\n",
    "data = data[features]\n",
    "\n",
    "# Normalize the features\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=features)\n",
    "\n",
    "# Prepare data for LSTM\n",
    "def create_inout_sequences(input_data, tw):\n",
    "    inout_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw-1):  # Ensure there's room for the label\n",
    "        train_seq = torch.tensor(input_data.iloc[i:i+tw].values, dtype=torch.float32)\n",
    "        train_label = torch.tensor(input_data.iloc[i+tw:i+tw+1].values[:, -1], dtype=torch.float32)  # Assuming last column is target\n",
    "        inout_seq.append((train_seq, train_label))\n",
    "    return inout_seq\n",
    "\n",
    "seq_length = 24  # Using 24 hours of data to predict the next hour\n",
    "all_data = create_inout_sequences(data_scaled, seq_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Define DLinear Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the LSTM-Enhanced Linear Regression Model\n",
    "class DLinear(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size):\n",
    "        super(DLinear, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq)\n",
    "        predictions = self.linear(lstm_out[:, -1, :])  # Only take the output from the last time step\n",
    "        return predictions\n",
    "\n",
    "input_size = 7  # Number of features, including 'Appliances' if it is part of the input\n",
    "hidden_layer_size = 100\n",
    "output_size = 1\n",
    "\n",
    "model = DLinear(input_size, hidden_layer_size, output_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, optimizer, loss_function, epochs=3):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        for seq, labels in train_data:\n",
    "            optimizer.zero_grad()  # Clears old gradients from the last step\n",
    "            seq = seq.reshape(1, seq_length, -1)  # Reshape input to match LSTM expected input\n",
    "            y_pred = model(seq)  # Forward pass: compute the output\n",
    "            loss = loss_function(y_pred, labels)  # Compute the loss\n",
    "            loss.backward()  # Compute gradients\n",
    "            optimizer.step()  # Update the weights\n",
    "            print(f'Epoch {epoch+1}, Loss: {loss.item()}')  # Print loss for each epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Define LSTM-Enhanced Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLinear(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, output_size):\n",
    "        super(DLinear, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        # Ensure input is of the shape [batch_size, seq_length, num_features]\n",
    "        lstm_out, _ = self.lstm(input_seq)\n",
    "        predictions = self.linear(lstm_out.view(-1, self.hidden_layer_size))\n",
    "        return predictions[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6: Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, val_data, optimizer, loss_function, epochs=3):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Switch to training mode\n",
    "        train_losses = []\n",
    "        for seq, labels in train_data:\n",
    "            optimizer.zero_grad()\n",
    "            seq = seq.reshape(1, seq_length, -1)\n",
    "            y_pred = model(seq)\n",
    "            loss = loss_function(y_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(loss.item())\n",
    "        \n",
    "        model.eval()  # Switch to evaluation mode for validation\n",
    "        val_losses = []\n",
    "        for seq, labels in val_data:\n",
    "            seq = seq.reshape(1, seq_length, -1)\n",
    "            y_pred = model(seq)\n",
    "            val_loss = loss_function(y_pred, labels)\n",
    "            val_losses.append(val_loss.item())\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Training Loss: {np.mean(train_losses):.4f}, Validation Loss: {np.mean(val_losses):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data, loss_function):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for seq, labels in test_data:\n",
    "            seq = seq.reshape(1, seq_length, -1)\n",
    "            y_pred = model(seq)\n",
    "            test_loss = loss_function(y_pred, labels)\n",
    "            test_losses.append(test_loss.item())\n",
    "    print(f'Average Test Loss: {np.mean(test_losses):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8: Run the Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mustafa/anaconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Training Loss: 0.0044, Validation Loss: 0.0041\n",
      "Epoch 2: Training Loss: 0.0040, Validation Loss: 0.0040\n",
      "Epoch 3: Training Loss: 0.0039, Validation Loss: 0.0039\n",
      "Average Test Loss: 0.0039\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_data, test_data, optimizer, loss_function, epochs=3)\n",
    "evaluate_model(model, test_data, loss_function)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
